{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import sparknlp # nlp processing\n",
    "from sklearn.model_selection import train_test_split # splitting data\n",
    "import keras\n",
    "import matplotlib.pyplot as plt # visualisation\n",
    "import seaborn as sns # visualisation \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState = np.random.RandomState(seed=42) # for creating same randomness in each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.5.0\n",
      "Apache Spark version:  2.4.5\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sql = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(\"questionBertEmbeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+--------------------------------------+--------------------------------------+-----+\n",
      "|    id|  qid1|  qid2|question1_finished_sentence_embeddings|question2_finished_sentence_embeddings|label|\n",
      "+------+------+------+--------------------------------------+--------------------------------------+-----+\n",
      "|119994|194709|194710|                  [[0.3533832728862...|                  [[0.1582194119691...|  1.0|\n",
      "|119995|194711|171467|                  [[0.3274492025375...|                  [[0.8858540058135...|  0.0|\n",
      "|119996|194712|194713|                  [[-0.307045459747...|                  [[0.4329249262809...|  0.0|\n",
      "|119997|111655| 64454|                  [[-0.437017947435...|                  [[-0.389505982398...|  0.0|\n",
      "|119998| 67996|194714|                  [[0.6548286676406...|                  [[0.4485912322998...|  1.0|\n",
      "+------+------+------+--------------------------------------+--------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- qid1: long (nullable = true)\n",
      " |-- qid2: long (nullable = true)\n",
      " |-- question1_finished_sentence_embeddings: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      " |-- question2_finished_sentence_embeddings: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renamed = df.withColumnRenamed(\"question1_finished_sentence_embeddings\",\"features1\")\\\n",
    ".withColumnRenamed(\"question2_finished_sentence_embeddings\",\"features2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- qid1: long (nullable = true)\n",
      " |-- qid2: long (nullable = true)\n",
      " |-- features1: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      " |-- features2: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_renamed.randomSplit([.8, .2], seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(df, chunks=10):\n",
    "    x_train_1 = []\n",
    "    x_train_2 = []\n",
    "    y_train = []\n",
    "\n",
    "    row_count = df.count()\n",
    "    i = 0\n",
    "    \n",
    "    chunks = df.randomSplit(weights=[1/chunks] * chunks)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        rows = chunk.collect()\n",
    "        for row in rows:\n",
    "            if i % 100000 == 0:\n",
    "                print('row {} / {} ({:.1f} %)'.format(i, row_count, 100 * i / row_count))\n",
    "            f1 = np.array(row['features1'][0]).reshape(-1,1)\n",
    "            f2 = np.array(row['features2'][0]).reshape(-1,1)\n",
    "            label = row['label']\n",
    "            x_train_1.append(f1)\n",
    "            x_train_2.append(f2)\n",
    "            y_train.append(label)\n",
    "            i += 1\n",
    "\n",
    "    #x_train = np.array([np.array(x_train_1), np.array(x_train_2)])\n",
    "    y_train = np.array(y_train)\n",
    "    return x_train_1, x_train_2, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 / 323344 (0.0 %)\n",
      "row 100000 / 323344 (30.9 %)\n",
      "row 200000 / 323344 (61.9 %)\n",
      "row 300000 / 323344 (92.8 %)\n"
     ]
    }
   ],
   "source": [
    "x_train_1, x_train_2, y_train = build_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1 = sequence.pad_sequences(x_train_1, maxlen=768)\n",
    "x_train_2 = sequence.pad_sequences(x_train_2, maxlen=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0 / 80943 (0.0 %)\n"
     ]
    }
   ],
   "source": [
    "x_test_1, x_test_2, y_test = build_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1 = sequence.pad_sequences(x_test_1, maxlen=768)\n",
    "x_test_2 = sequence.pad_sequences(x_test_2, maxlen=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323344, 768, 1) (323344, 768, 1)\n",
      "(80943, 768, 1) (80943, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_1.shape, x_train_2.shape)\n",
    "print(x_test_1.shape, x_test_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels:\n",
      " 0.0    204157\n",
      "1.0    119187\n",
      "dtype: int64\n",
      "Test Labels:\n",
      " 0.0    50867\n",
      "1.0    30076\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Train Labels:\\n', pd.Series(y_train).value_counts())\n",
    "print('Test Labels:\\n', pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Siamese Approach (Distance Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    _input = Input(shape=input_shape)\n",
    "    x = Flatten()(_input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(_input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, 'float64')))\n",
    "\n",
    "def absolute_loss(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network definition\n",
    "base_network = create_base_network((768, 1))\n",
    "\n",
    "input_a = Input(shape=(768, 1))\n",
    "input_b = Input(shape=(768, 1))\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "rms = RMSprop()\n",
    "model.compile(loss='binary_crossentropy', optimizer=rms, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323344 samples, validate on 80943 samples\n",
      "Epoch 1/5\n",
      "323344/323344 [==============================] - 24s 74us/step - loss: 0.6658 - acc: 0.6543 - val_loss: 0.8827 - val_acc: 0.6556\n",
      "Epoch 2/5\n",
      "323344/323344 [==============================] - 23s 71us/step - loss: 0.6905 - acc: 0.6637 - val_loss: 0.9173 - val_acc: 0.6502\n",
      "Epoch 3/5\n",
      "323344/323344 [==============================] - 23s 71us/step - loss: 0.7310 - acc: 0.6582 - val_loss: 0.9943 - val_acc: 0.6445\n",
      "Epoch 4/5\n",
      "323344/323344 [==============================] - 23s 72us/step - loss: 0.7681 - acc: 0.6531 - val_loss: 1.0502 - val_acc: 0.6380\n",
      "Epoch 5/5\n",
      "323344/323344 [==============================] - 24s 73us/step - loss: 0.7868 - acc: 0.6506 - val_loss: 1.0503 - val_acc: 0.6437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13f4f6510>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train_1, x_train_2], y_train,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([x_test_1, x_test_2], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([x_test_1, x_test_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = np.array([0.0 if x<0.5 else 1.0 for x in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.97      0.79     50867\n",
      "         1.0       0.80      0.20      0.32     30076\n",
      "\n",
      "    accuracy                           0.68     80943\n",
      "   macro avg       0.73      0.59      0.56     80943\n",
      "weighted avg       0.72      0.68      0.62     80943\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import recurrent, concatenate, Embedding\n",
    "\n",
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 50\n",
    "HIDDEN_SIZE = 250\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = Input(shape=(768,1))\n",
    "encoded_question1 = RNN(HIDDEN_SIZE)(question1)\n",
    "\n",
    "question2 = Input(shape=(768,1))\n",
    "encoded_question2 = RNN(HIDDEN_SIZE)(question2)\n",
    "\n",
    "merged = concatenate([encoded_question1, encoded_question2])\n",
    "preds = Dense(1, activation='softmax')(merged)\n",
    "\n",
    "model = Model([question1, question2], preds)\n",
    "rms = RMSprop()\n",
    "model.compile(optimizer=rms,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 31296/323344 [=>............................] - ETA: 4:32:31 - loss: 10.0363 - acc: 0.3705"
     ]
    }
   ],
   "source": [
    "model.fit([x_train_1, x_train_2], y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=([x_test_1, x_test_2], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparknlp",
   "language": "python",
   "name": "sparknlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
