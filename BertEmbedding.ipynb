{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import sparknlp # nlp processing\n",
    "from sklearn.model_selection import train_test_split # splitting data\n",
    "\n",
    "import matplotlib.pyplot as plt # visualisation\n",
    "import seaborn as sns # visualisation \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState = np.random.RandomState(seed=42) # for creating same randomness in each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.5.0\n",
      "Apache Spark version:  2.4.5\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- qid1: string (nullable = true)\n",
      " |-- qid2: string (nullable = true)\n",
      " |-- question1: string (nullable = true)\n",
      " |-- question2: string (nullable = true)\n",
      " |-- is_duplicate: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sql = SQLContext(spark)\n",
    "\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"dataset/clean_data.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_partial_pipeline(column):\n",
    "    document_assembler = DocumentAssembler() \\\n",
    "        .setInputCol(column) \\\n",
    "        .setOutputCol(column+\"_document\")\\\n",
    "        .setCleanupMode(\"shrink\") \n",
    "    \n",
    "    sentence_detector = SentenceDetector() \\\n",
    "        .setInputCols([column+\"_document\"]) \\\n",
    "        .setOutputCol(column+\"_sentence\") \\\n",
    "        .setUseAbbreviations(True)\n",
    "    \n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([column+\"_sentence\"]) \\\n",
    "        .setOutputCol(column+\"_token\")\n",
    "    \n",
    "    spell_checker = NorvigSweetingApproach() \\\n",
    "        .setInputCols([column+\"_token\"]) \\\n",
    "        .setOutputCol(column+\"_checked\") \\\n",
    "        .setDictionary(\"./spell/coca2017.txt\", \"[a-zA-Z]+\")\n",
    "    \n",
    "    normalizer = Normalizer() \\\n",
    "        .setInputCols([column+\"_checked\"]) \\\n",
    "        .setOutputCol(column+\"_normalized\")\n",
    "    \n",
    "    lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
    "        .setInputCols([column+\"_normalized\"]) \\\n",
    "        .setOutputCol(column+\"_lemma\")\n",
    "    \n",
    "    stopwords_cleaner = StopWordsCleaner()\\\n",
    "        .setInputCols(column+\"_lemma\")\\\n",
    "        .setOutputCol(column+\"_cleanTokens\")\\\n",
    "        .setCaseSensitive(False)\n",
    "   \n",
    "    finisher = Finisher() \\\n",
    "        .setInputCols([column+\"_cleanTokens\"]) \\\n",
    "        .setOutputCols([column+\"_finished\"])\\\n",
    "        .setIncludeMetadata(False)\\\n",
    "        .setCleanAnnotations(True)\n",
    "    \n",
    "    return [document_assembler, sentence_detector, tokenizer, spell_checker, normalizer, lemma, stopwords_cleaner, finisher]\n",
    "\n",
    "def preprocessing_pipeline():\n",
    "\n",
    "    q1_stages = preprocessing_partial_pipeline(\"question1\")\n",
    "    \n",
    "    q2_stages = preprocessing_partial_pipeline(\"question2\")\n",
    "     \n",
    "    pipeline = Pipeline(stages=q1_stages+q2_stages)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited = df.limit(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='0', qid1='1', qid2='2', question1='What is the step by step guide to invest in share market in india?', question2='What is the step by step guide to invest in share market?', is_duplicate='0'),\n",
       " Row(id='1', qid1='3', qid2='4', question1='What is the story of Kohinoor (Koh-i-Noor) Diamond?', question2='What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', is_duplicate='0'),\n",
       " Row(id='2', qid1='5', qid2='6', question1='How can I increase the speed of my internet connection while using a VPN?', question2='How can Internet speed be increased by hacking through DNS?', is_duplicate='0'),\n",
       " Row(id='3', qid1='7', qid2='8', question1='Why am I mentally very lonely? How can I solve it?', question2='Find the remainder when [math]23^{24}[/math] is divided by 24,23?', is_duplicate='0'),\n",
       " Row(id='4', qid1='9', qid2='10', question1='Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?', question2='Which fish would survive in salt water?', is_duplicate='0')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before Preprocessing \n",
    "df_limited.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "pre_pipeline = preprocessing_pipeline()\n",
    "model = pre_pipeline.fit(df_limited)\n",
    "df_processed = model.transform(df_limited).persist().select(\"question1\", \"question2\", \"question1_finished\", \"question2_finished\", \"is_duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(question1='What is the step by step guide to invest in share market in india?', question2='What is the step by step guide to invest in share market?', question1_finished=['step', 'step', 'guide', 'invest', 'share', 'market', 'india'], question2_finished=['step', 'step', 'guide', 'invest', 'share', 'market'], is_duplicate='0'),\n",
       " Row(question1='What is the story of Kohinoor (Koh-i-Noor) Diamond?', question2='What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', question1_finished=['story', 'kohinoor', 'KohiNoor', 'diamond'], question2_finished=['happen', 'indian', 'government', 'steal', 'kohinoor', 'KohiNoor', 'diamond', 'back'], is_duplicate='0'),\n",
       " Row(question1='How can I increase the speed of my internet connection while using a VPN?', question2='How can Internet speed be increased by hacking through DNS?', question1_finished=['increase', 'speed', 'internet', 'connection', 'use', 'VPN'], question2_finished=['internet', 'speed', 'increase', 'hack', 'DNS'], is_duplicate='0'),\n",
       " Row(question1='Why am I mentally very lonely? How can I solve it?', question2='Find the remainder when [math]23^{24}[/math] is divided by 24,23?', question1_finished=['mentally', 'lonely', 'solve'], question2_finished=['wind', 'remainder', 'mathmath', 'divide'], is_duplicate='0'),\n",
       " Row(question1='Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?', question2='Which fish would survive in salt water?', question1_finished=['one', 'dissolve', 'water', 'quikly', 'sugar', 'salt', 'methane', 'carbon', 'di', 'oxide'], question2_finished=['fish', 'survive', 'salt', 'water'], is_duplicate='0')]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_processed.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing + Bert Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_partial(column):\n",
    "    document_assembler = DocumentAssembler() \\\n",
    "        .setInputCol(column) \\\n",
    "        .setOutputCol(column+\"_document\")\\\n",
    "        .setCleanupMode(\"shrink\") \n",
    "    \n",
    "    sentence_detector = SentenceDetector() \\\n",
    "        .setInputCols([column+\"_document\"]) \\\n",
    "        .setOutputCol(column+\"_sentence\") \\\n",
    "        .setUseAbbreviations(True)\n",
    "    \n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([column+\"_sentence\"]) \\\n",
    "        .setOutputCol(column+\"_token\")\n",
    "    \n",
    "    spell_checker = NorvigSweetingApproach() \\\n",
    "        .setInputCols([column+\"_token\"]) \\\n",
    "        .setOutputCol(column+\"_checked\") \\\n",
    "        .setDictionary(\"./spell/coca2017.txt\", \"[a-zA-Z]+\")\n",
    "    \n",
    "    normalizer = Normalizer() \\\n",
    "        .setInputCols([column+\"_checked\"]) \\\n",
    "        .setOutputCol(column+\"_normalized\")\n",
    "    \n",
    "    lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
    "        .setInputCols([column+\"_normalized\"]) \\\n",
    "        .setOutputCol(column+\"_lemma\")\n",
    "   \n",
    "    stopwords_cleaner = StopWordsCleaner()\\\n",
    "        .setInputCols(column+\"_lemma\")\\\n",
    "        .setOutputCol(column+\"_cleanTokens\")\\\n",
    "        .setCaseSensitive(False)\n",
    "    \n",
    "    bert_embeddings = BertEmbeddings\\\n",
    "        .pretrained('bert_base_cased', 'en') \\\n",
    "        .setInputCols([column+\"_document\",column+\"_cleanTokens\"])\\\n",
    "        .setOutputCol(column+\"_bert\")\\\n",
    "        .setCaseSensitive(False)\\\n",
    "        .setPoolingLayer(0)\n",
    "\n",
    "    embeddingsSentence = SentenceEmbeddings() \\\n",
    "          .setInputCols([column+\"_document\", column+\"_bert\"]) \\\n",
    "          .setOutputCol(column+\"_sentence_embeddings\") \\\n",
    "          .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "    embeddings_finisher = EmbeddingsFinisher() \\\n",
    "        .setInputCols([column+\"_sentence_embeddings\"]) \\\n",
    "        .setOutputCols([column+\"_finished_sentence_embeddings\"]) \\\n",
    "        .setOutputAsVector(True)\\\n",
    "        .setCleanAnnotations(False)\n",
    "\n",
    "    return [document_assembler, sentence_detector, tokenizer, spell_checker, normalizer, lemma, \\\n",
    "            stopwords_cleaner, bert_embeddings, embeddingsSentence, embeddings_finisher]\n",
    "\n",
    "def bert_pipeline():\n",
    "     \n",
    "    q1_stages = bert_partial(\"question1\")\n",
    "    \n",
    "    q2_stages = bert_partial(\"question2\")\n",
    "    \n",
    "    label_stringIdx = StringIndexer(inputCol = \"is_duplicate\", outputCol = \"label\")\n",
    "    \n",
    "    classsifierdl = ClassifierDLApproach()\\\n",
    "        .setInputCols([\"question1_sentence_embeddings\",\"question2_sentence_embeddings\"])\\\n",
    "        .setOutputCol(\"class\")\\\n",
    "        .setLabelColumn(\"label\")\\\n",
    "        .setMaxEpochs(15)\\\n",
    "        .setEnableOutputLogs(True)\n",
    "    \n",
    "    pipeline = Pipeline(stages=q1_stages+q2_stages+[label_stringIdx, classsifierdl])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n",
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "nlp_pipeline_bert = bert_pipeline()\n",
    "\n",
    "nlp_model_bert = nlp_pipeline_bert.fit(df_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "df = nlp_model_bert.transform(df_limited).select('label', 'question1', 'question2', 'class.result').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_bert = nlp_model_bert.transform(df_limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = df['result'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   label      2000 non-null   float64\n",
      " 1   question1  2000 non-null   object \n",
      " 2   question2  2000 non-null   object \n",
      " 3   result     2000 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'] = df['result'].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   label      2000 non-null   float64\n",
      " 1   question1  2000 non-null   object \n",
      " 2   question2  2000 non-null   object \n",
      " 3   result     2000 non-null   float64\n",
      "dtypes: float64(2), object(2)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          question1  \\\n",
       "0    0.0  What is the step by step guide to invest in sh...   \n",
       "1    0.0  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2    0.0  How can I increase the speed of my internet co...   \n",
       "3    0.0  Why am I mentally very lonely? How can I solve...   \n",
       "4    0.0  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  result  \n",
       "0  What is the step by step guide to invest in sh...     0.0  \n",
       "1  What would happen if the Indian government sto...     0.0  \n",
       "2  How can Internet speed be increased by hacking...     0.0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...     0.0  \n",
       "4            Which fish would survive in salt water?     0.0  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      1.00      0.77      1250\n",
      "         1.0       0.00      0.00      0.00       741\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         3.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "         5.0       0.00      0.00      0.00         1\n",
      "         6.0       0.00      0.00      0.00         1\n",
      "         7.0       0.00      0.00      0.00         1\n",
      "         8.0       0.00      0.00      0.00         1\n",
      "         9.0       0.00      0.00      0.00         1\n",
      "        10.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.06      0.09      0.07      2000\n",
      "weighted avg       0.39      0.62      0.48      2000\n",
      "\n",
      "0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muradbozik/.pyenv/versions/3.7.7/envs/sparknlp/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df.label, df.result))\n",
    "print(accuracy_score(df.label, df.result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>10.0</td>\n",
       "      <td>\"Is there a \"\"blind trust\"\" provision for Amer...</td>\n",
       "      <td>and how is it enforced?\"</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                          question1  \\\n",
       "813   10.0  \"Is there a \"\"blind trust\"\" provision for Amer...   \n",
       "\n",
       "                     question2  result  \n",
       "813   and how is it enforced?\"     0.0  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparknlp",
   "language": "python",
   "name": "sparknlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
