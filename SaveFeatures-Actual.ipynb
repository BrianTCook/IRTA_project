{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import sparknlp # nlp processing\n",
    "from sklearn.model_selection import train_test_split # splitting data\n",
    "\n",
    "import matplotlib.pyplot as plt # visualisation\n",
    "import seaborn as sns # visualisation \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomState = np.random.RandomState(seed=42) # for creating same randomness in each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark NLP version:  2.5.0\n",
      "Apache Spark version:  2.4.5\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()\n",
    "\n",
    "print(\"Spark NLP version: \", sparknlp.version())\n",
    "print(\"Apache Spark version: \", spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import *\n",
    "from sparknlp.base import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sql = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_partial(column):\n",
    "    document_assembler = DocumentAssembler() \\\n",
    "        .setInputCol(column) \\\n",
    "        .setOutputCol(column+\"_document\")\\\n",
    "        .setCleanupMode(\"shrink\") \n",
    "    \n",
    "    sentence_detector = SentenceDetector() \\\n",
    "        .setInputCols([column+\"_document\"]) \\\n",
    "        .setOutputCol(column+\"_sentence\") \\\n",
    "        .setUseAbbreviations(True)\n",
    "    \n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([column+\"_sentence\"]) \\\n",
    "        .setOutputCol(column+\"_token\")\n",
    "    \n",
    "    spell_checker = NorvigSweetingApproach() \\\n",
    "        .setInputCols([column+\"_token\"]) \\\n",
    "        .setOutputCol(column+\"_checked\") \\\n",
    "        .setDictionary(\"./spell/coca2017.txt\", \"[a-zA-Z]+\")\n",
    "    \n",
    "    normalizer = Normalizer() \\\n",
    "        .setInputCols([column+\"_checked\"]) \\\n",
    "        .setOutputCol(column+\"_normalized\")\n",
    "    \n",
    "    lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
    "        .setInputCols([column+\"_normalized\"]) \\\n",
    "        .setOutputCol(column+\"_lemma\")\n",
    "   \n",
    "    stopwords_cleaner = StopWordsCleaner()\\\n",
    "        .setInputCols(column+\"_lemma\")\\\n",
    "        .setOutputCol(column+\"_cleanTokens\")\\\n",
    "        .setCaseSensitive(False)\n",
    "    \n",
    "    bert_embeddings = BertEmbeddings\\\n",
    "        .pretrained('bert_base_cased', 'en') \\\n",
    "        .setInputCols([column+\"_document\",column+\"_cleanTokens\"])\\\n",
    "        .setOutputCol(column+\"_bert\")\\\n",
    "        .setCaseSensitive(False)\\\n",
    "        .setPoolingLayer(0)\n",
    "\n",
    "    embeddingsSentence = SentenceEmbeddings() \\\n",
    "          .setInputCols([column+\"_document\", column+\"_bert\"]) \\\n",
    "          .setOutputCol(column+\"_sentence_embeddings\") \\\n",
    "          .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "    embeddings_finisher = EmbeddingsFinisher() \\\n",
    "        .setInputCols([column+\"_sentence_embeddings\"]) \\\n",
    "        .setOutputCols([column+\"_finished_sentence_embeddings\"]) \\\n",
    "        .setOutputAsVector(True)\\\n",
    "        .setCleanAnnotations(True)\n",
    "\n",
    "    return [document_assembler, sentence_detector, tokenizer, spell_checker, normalizer, lemma, \\\n",
    "            stopwords_cleaner, bert_embeddings, embeddingsSentence, embeddings_finisher]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_pipeline():\n",
    "    \n",
    "    q1_stages = bert_partial(\"question1\")\n",
    "    \n",
    "    q2_stages = bert_partial(\"question2\")\n",
    "    \n",
    "    label_stringIdx = StringIndexer(inputCol = \"is_duplicate\", outputCol = \"label\")\n",
    "    \n",
    "    pipeline = Pipeline(stages=q1_stages+q2_stages+[label_stringIdx])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n",
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n",
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "nlp_pipeline_bert = bert_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset/clean_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, df_part in enumerate(np.array_split(data, 202)):\n",
    "    chunk = sql.createDataFrame(df_part)\n",
    "    nlp_model_bert = nlp_pipeline_bert.fit(chunk)\n",
    "    \n",
    "    result = nlp_model_bert.transform(chunk)\n",
    "    \n",
    "    if ix == 0:\n",
    "        result_df = result\n",
    "    else:\n",
    "        result_df.unionAll(result)\n",
    "    if ix == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- qid1: long (nullable = true)\n",
      " |-- qid2: long (nullable = true)\n",
      " |-- question1: string (nullable = true)\n",
      " |-- question2: string (nullable = true)\n",
      " |-- is_duplicate: long (nullable = true)\n",
      " |-- question1_finished_sentence_embeddings: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      " |-- question2_finished_sentence_embeddings: array (nullable = true)\n",
      " |    |-- element: vector (containsNull = true)\n",
      " |-- label: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+--------------------+--------------------+--------------------------------------+--------------------------------------+-----+\n",
      "| id|qid1|qid2|           question1|           question2|question1_finished_sentence_embeddings|question2_finished_sentence_embeddings|label|\n",
      "+---+----+----+--------------------+--------------------+--------------------------------------+--------------------------------------+-----+\n",
      "|  0|   1|   2|What is the step ...|What is the step ...|                  [[0.1943234652280...|                  [[0.2024581581354...|  0.0|\n",
      "|  1|   3|   4|What is the story...|What would happen...|                  [[-0.479584932327...|                  [[0.0168425478041...|  0.0|\n",
      "|  2|   5|   6|How can I increas...|How can Internet ...|                  [[0.3350400924682...|                  [[-0.360031187534...|  0.0|\n",
      "|  3|   7|   8|Why am I mentally...|Find the remainde...|                  [[0.0855144485831...|                  [[-0.650472879409...|  0.0|\n",
      "|  4|   9|  10|Which one dissolv...|Which fish would ...|                  [[0.1552668064832...|                  [[-0.541451036930...|  0.0|\n",
      "+---+----+----+--------------------+--------------------+--------------------------------------+--------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.drop(\"is_duplicate\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.drop(\"is_duplicate\").write.save(\"questionBertEmbeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparknlp",
   "language": "python",
   "name": "sparknlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
